{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMXEaXb8Hka/hmNyDhlwWIv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"7yghUkW8LgyP"},"outputs":[],"source":["import os\n","import yfinance as yf\n","import pandas as pd\n","import requests\n","from bs4 import BeautifulSoup\n","import matplotlib\n","matplotlib.use('Agg')\n","import matplotlib.pyplot as plt\n","import matplotlib.dates as mdates\n","import csv\n","from PIL import Image, ImageDraw\n","\n","def get_sp500_tickers():\n","    try:\n","        url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n","        response = requests.get(url)\n","        soup = BeautifulSoup(response.text, 'html.parser')\n","        table = soup.find('table', {'id': 'constituents'})\n","        tickers = []\n","        for row in table.findAll('tr')[1:]:\n","            ticker = row.findAll('td')[0].text.strip()\n","            tickers.append(ticker)\n","        return tickers\n","    except Exception as e:\n","        print(f\"Error fetching S&P 500 tickers: {e}\")\n","        return []\n","\n","def get_nasdaq100_tickers():\n","    try:\n","        url = \"https://en.wikipedia.org/wiki/NASDAQ-100\"\n","        response = requests.get(url)\n","        soup = BeautifulSoup(response.text, 'html.parser')\n","        table = soup.find('table', {'id': 'constituents'})\n","        tickers = []\n","        for row in table.findAll('tr')[1:]:\n","            ticker = row.findAll('td')[1].text.strip()\n","            tickers.append(ticker)\n","        return tickers\n","    except Exception as e:\n","        print(f\"Error fetching NASDAQ-100 tickers: {e}\")\n","        return []\n","\n","def get_nse_tickers():\n","    # Static list or alternative method, if scraping fails\n","    try:\n","        url = \"https://www.moneycontrol.com/stocks/marketinfo/marketcap/nse/index.html\"\n","        response = requests.get(url)\n","        soup = BeautifulSoup(response.text, 'html.parser')\n","        table = soup.find('table', {'class': 'tbldata14 bdrtpg'})\n","        tickers = []\n","        for row in table.findAll('tr')[1:]:\n","            ticker = row.findAll('td')[0].text.strip().split(\" \")[0]\n","            tickers.append(ticker)\n","        return tickers\n","    except Exception as e:\n","        print(f\"Error fetching NSE tickers: {e}\")\n","        return []\n","\n","def calculate_rsi(df, window=14):\n","    delta = df['Close'].diff(1)\n","    gain = delta.where(delta > 0, 0)\n","    loss = -delta.where(delta < 0, 0)\n","\n","    avg_gain = gain.rolling(window=window, min_periods=1).mean()\n","    avg_loss = loss.rolling(window=window, min_periods=1).mean()\n","\n","    rs = avg_gain / avg_loss\n","    rsi = 100 - (100 / (1 + rs))\n","\n","    df['RSI'] = rsi\n","    return df\n","\n","def find_rsi_signals(df):\n","    df['Buy_Signal'] = (df['RSI'] < 30) & (df['RSI'].shift(1) >= 30)\n","    df['Sell_Signal'] = (df['RSI'] > 70) & (df['RSI'].shift(1) <= 70)\n","    return df\n","\n","def get_data(ticker, start, end):\n","    df = yf.download(ticker, start=start, end=end)\n","    return df\n","\n","def plot_rsi_yearly(ticker, df, year, output_dir):\n","    df_year = df[df['Date'].dt.year == year]\n","    if df_year.empty:\n","        return None, None\n","\n","    fig, ax = plt.subplots(figsize=(10, 6))\n","    ax.plot(df_year['Date'], df_year['RSI'], label='RSI')\n","    ax.axhline(70, color='red', linestyle='--', label='Overbought (70)')\n","    ax.axhline(30, color='green', linestyle='--', label='Oversold (30)')\n","\n","    buy_signals = df_year[df_year['Buy_Signal']]\n","    sell_signals = df_year[df_year['Sell_Signal']]\n","    bounding_boxes = []\n","\n","    filename = f\"{ticker}_{year}_RSI.png\"\n","    filepath = os.path.join(output_dir, filename)\n","    plt.savefig(filepath)\n","    plt.close(fig)\n","\n","    img = Image.open(filepath)\n","    draw = ImageDraw.Draw(img)\n","    img_width, img_height = img.size\n","\n","    for i, row in buy_signals.iterrows():\n","        date_num = mdates.date2num(row['Date'])\n","        x, y = ax.transData.transform((date_num, row['RSI']))\n","        y = img_height - y\n","        box_width = 40\n","        box_height = 40\n","        xmin = int(x - box_width // 2)\n","        ymin = int(y - box_height // 2)\n","        xmax = int(x + box_width // 2)\n","        ymax = int(y + box_width // 2)\n","        bounding_boxes.append([xmin, ymin, xmax, ymax, \"buy_signal\"])\n","\n","    for i, row in sell_signals.iterrows():\n","        date_num = mdates.date2num(row['Date'])\n","        x, y = ax.transData.transform((date_num, row['RSI']))\n","        y = img_height - y\n","        box_width = 40\n","        box_height = 40\n","        xmin = int(x - box_width // 2)\n","        ymin = int(y - box_height // 2)\n","        xmax = int(x + box_width // 2)\n","        ymax = int(y + box_width // 2)\n","        bounding_boxes.append([xmin, ymin, xmax, ymax, \"sell_signal\"])\n","\n","    img.save(filepath)\n","\n","    return bounding_boxes, filename\n","\n","def visualize_bounding_boxes(image_dir, annotations_file, num_images=5):\n","    annotations = pd.read_csv(annotations_file)\n","    sample_images = annotations['image_filename'].unique()[:num_images]\n","\n","    for image_filename in sample_images:\n","        image_path = os.path.join(image_dir, image_filename)\n","        img = Image.open(image_path)\n","        draw = ImageDraw.Draw(img)\n","\n","        image_annotations = annotations[annotations['image_filename'] == image_filename]\n","\n","        for _, row in image_annotations.iterrows():\n","            xmin = row['xmin']\n","            ymin = row['ymin']\n","            xmax = row['xmax']\n","            ymax = row['ymax']\n","            label = row['label']\n","            color = \"red\" if label == \"buy_signal\" else \"blue\"\n","\n","            draw.rectangle([xmin, ymin, xmax, ymax], outline=color)\n","\n","        img.show()\n","\n","# Combine all tickers\n","tickers = get_sp500_tickers() + get_nasdaq100_tickers() + get_nse_tickers()\n","\n","if tickers:\n","    # Create output directory\n","    output_dir = 'rsi_images'\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    annotations = []\n","    years = range(2000, 2020)  # Extend the range to nearly 20 years\n","\n","    # Process each ticker\n","    try:\n","        for ticker in tickers:\n","            print(f\"Processing ticker: {ticker}\")\n","            df = get_data(ticker, start='2000-01-01', end='2019-12-31')\n","            if df.empty:\n","                print(f\"No data for {ticker}. Skipping.\")\n","                continue\n","            df['Date'] = pd.to_datetime(df.index)\n","            df = calculate_rsi(df)\n","            df = find_rsi_signals(df)\n","\n","            for year in years:\n","                bounding_boxes, filename = plot_rsi_yearly(ticker, df, year, output_dir)\n","                if filename and bounding_boxes:\n","                    for bbox in bounding_boxes:\n","                        xmin, ymin, xmax, ymax, label = bbox\n","                        annotations.append([filename, xmin, ymin, xmax, ymax, label])\n","\n","    except Exception as e:\n","        print(f\"An error occurred during processing: {e}\")\n","\n","    # Save annotations to CSV\n","    try:\n","        annotations_file = 'rsi_annotations.csv'\n","        with open(annotations_file, 'w', newline='') as file:\n","            writer = csv.writer(file)\n","            writer.writerow([\"image_filename\", \"xmin\", \"ymin\", \"xmax\", \"ymax\", \"label\"])\n","            writer.writerows(annotations)\n","        print(f\"Annotations saved to {annotations_file}.\")\n","    except Exception as e:\n","        print(f\"An error occurred while saving annotations: {e}\")\n","\n","    # Visualize bounding boxes\n","    visualize_bounding_boxes(output_dir, annotations_file)\n","else:\n","    print(\"No tickers to process.\")\n"]}]}